{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6.3 CNN AE.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"7ra6s1cQE8Wu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4e9c9a90-fba7-4fc0-a434-ec554dede45a","executionInfo":{"status":"ok","timestamp":1538059627015,"user_tz":-540,"elapsed":1264,"user":{"displayName":"박훈범","photoUrl":"","userId":"14931571077491814984"}}},"cell_type":"code","source":["from keras import layers, models"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"jRhkfTRtFWis","colab_type":"text"},"cell_type":"markdown","source":["## # AE 모델링"]},{"metadata":{"id":"Gyr11p6PFCca","colab_type":"code","colab":{}},"cell_type":"code","source":["def Conv2D(filters, kernel_size, padding='same', activation='relu'):\n","    return layers.Conv2D(filters, kernel_size, padding=padding, activation=activation)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z6wj7Q3XFY3w","colab_type":"code","colab":{}},"cell_type":"code","source":["class AE(models.Model):\n","    def __init__(self, org_shape=(1, 28, 28)):\n","        # Input\n","        original = layers.Input(shape=org_shape)\n","\n","        # encoding-1\n","        x = Conv2D(4, (3, 3))(original)\n","        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n","\n","        # encoding-2\n","        x = Conv2D(8, (3, 3))(x)\n","        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n","\n","        # encoding-3: encoding output: 7x7 pixels\n","        z = Conv2D(1, (7, 7))(x)\n","\n","        # decoding-1\n","        y = Conv2D(16, (3, 3))(z)\n","        y = layers.UpSampling2D((2, 2))(y)\n","\n","        # decoding-2\n","        y = Conv2D(8, (3, 3))(y)\n","        y = layers.UpSampling2D((2, 2))(y)\n","\n","        # decoding-3\n","        y = Conv2D(4, (3, 3))(y)\n","\n","        # decoding & Output\n","        decoded = Conv2D(1, (3, 3), activation='sigmoid')(y)\n","\n","        super().__init__(original, decoded)\n","        self.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QgzgvLusFe93","colab_type":"text"},"cell_type":"markdown","source":["## 데이터 불러오기"]},{"metadata":{"id":"6bzFtmzpGZAc","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import datasets"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BGOtxjpIFeUB","colab_type":"code","colab":{}},"cell_type":"code","source":["class DATA():\n","    def __init__(self):\n","        num_classes = 10\n","\n","        (x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n","        img_rows, img_cols = x_train.shape[1:]\n","\n","        if backend.image_data_format() == 'channels_first':\n","            x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","            x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","            input_shape = (1, img_rows, img_cols)\n","        else:\n","            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","            x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","            input_shape = (img_rows, img_cols, 1)\n","\n","        x_train = x_train.astype('float32')\n","        x_test = x_test.astype('float32')\n","        x_train /= 255\n","        x_test /= 255\n","\n","        y_train = keras.utils.to_categorical(y_train, num_classes)\n","        y_test = keras.utils.to_categorical(y_test, num_classes)\n","        \n","        self.input_shape = input_shape\n","        self.num_classes = num_classes\n","        self.x_train, self.y_train = x_train, y_train\n","        self.x_test, self.y_test = x_test, y_test"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RK-_IlyHFwIf","colab_type":"text"},"cell_type":"markdown","source":["## 학습 효과 분석"]},{"metadata":{"id":"4j6gD8YCFaxY","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aio00VJBFzA3","colab_type":"code","colab":{}},"cell_type":"code","source":["def plot_acc(history, title=None):\n","    # summarize history for accuracy\n","    if not isinstance(history, dict):\n","        history = history.history\n","\n","    plt.plot(history['acc'])\n","    plt.plot(history['val_acc'])\n","    if title is not None:\n","        plt.title(title)\n","    plt.ylabel('Accracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Training data', 'Validation data'], loc=0)\n","    # plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MrBLYl8VGDAA","colab_type":"code","colab":{}},"cell_type":"code","source":["def plot_loss(history, title=None):\n","    # summarize history for loss\n","    if not isinstance(history, dict):\n","        history = history.history\n","\n","    plt.plot(history['loss'])\n","    plt.plot(history['val_loss'])\n","    if title is not None:\n","        plt.title(title)\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Training data', 'Validation data'], loc=0)\n","    # plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zQoS4xNOGHjM","colab_type":"text"},"cell_type":"markdown","source":["## AE 결과 시각화\n"]},{"metadata":{"id":"EeO2s1gfGES5","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import backend \n","import keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bTTnOWG6GJcs","colab_type":"code","colab":{}},"cell_type":"code","source":["def show_ae(autoencoder, data):\n","    x_test = data.x_test\n","    decoded_imgs = autoencoder.predict(x_test)\n","    print(decoded_imgs.shape, data.x_test.shape)\n","\n","    if backend.image_data_format() == 'channels_first':\n","        N, n_ch, n_i, n_j = x_test.shape\n","    else:\n","        N, n_i, n_j, n_ch = x_test.shape\n","\n","    x_test = x_test.reshape(N, n_i, n_j)\n","    decoded_imgs = decoded_imgs.reshape(decoded_imgs.shape[0], n_i, n_j)\n","    \n","    n = 10\n","    plt.figure(figsize=(20, 4))\n","    for i in range(n):\n","\n","        ax = plt.subplot(2, n, i + 1)\n","        plt.imshow(x_test[i], cmap='gray')\n","        # plt.gray()\n","        ax.get_xaxis().set_visible(False)\n","        ax.get_yaxis().set_visible(False)\n","\n","        ax = plt.subplot(2, n, i + 1 + n)\n","        plt.imshow(decoded_imgs[i], cmap='gray')\n","        # plt.gray()\n","        ax.get_xaxis().set_visible(False)\n","        ax.get_yaxis().set_visible(False)\n","\n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9LqEArLSGLvz","colab_type":"text"},"cell_type":"markdown","source":["## 학습 및 확인"]},{"metadata":{"id":"TYphN37EGKzk","colab_type":"code","colab":{}},"cell_type":"code","source":["def main(epochs=20, batch_size=128):\n","    data = DATA()\n","    autoencoder = AE(data.input_shape)\n","\n","    history = autoencoder.fit(data.x_train, data.x_train,\n","                              epochs=epochs,\n","                              batch_size=batch_size,\n","                              shuffle=True,\n","                              validation_split=0.2)\n","\n","    plot_acc(history, '(a) 정확도 학습 곡선')\n","    plt.show()\n","    plot_loss(history, '(b) 손실 학습 곡선')\n","    plt.show()\n","\n","    show_ae(autoencoder, data)\n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mlck0eA1GOPn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":415},"outputId":"dfd2fc22-7b5c-4b33-e746-905160245f7f","executionInfo":{"status":"error","timestamp":1538059642167,"user_tz":-540,"elapsed":1624,"user":{"displayName":"박훈범","photoUrl":"","userId":"14931571077491814984"}}},"cell_type":"code","source":["if __name__ == '__main__':\n","    main()"],"execution_count":12,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-12-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-59380874646e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(epochs, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     history = autoencoder.fit(data.x_train, data.x_train,\n","\u001b[0;32m<ipython-input-3-830e11663437>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, org_shape)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adadelta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: super() takes at least 1 argument (0 given)"]}]},{"metadata":{"id":"Xp-zop8sGPYw","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}